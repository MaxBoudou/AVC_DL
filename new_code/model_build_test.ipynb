{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mjkkvjiOdH47"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg6imdAFhCpn"
   },
   "source": [
    "# Constructions des différents modules du UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69HFMegLhRge"
   },
   "source": [
    "Resnet Sub-block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IbBSC7MrhBxw"
   },
   "outputs": [],
   "source": [
    "def res_block(input, channels, kernel=(3,3), dil = (1,1), stride= (1,1), act= 'relu', bn= True, kernel_init='he_normal'): \n",
    "  \"\"\"Simple build of a 2D residual block containing 2 2D convolutions\n",
    "\n",
    "  Input --> Conv2D > ReLu > BN --> Conv2D > BN --> + > ReLU --> Output\n",
    "        |                                          |\n",
    "        +---------(compression conv2D 1x1)---------+\n",
    "\n",
    "  - input : Block input volume.\n",
    "  - channels : Number of output channels. If \"channels\" value is inferior to input channels, a compression is automatically made with a 1*1conv in the identity branch. \n",
    "  - kernel : Kernel size to use in all convolutions (except in the compression one).\n",
    "  - dil : Dilation to use (default = (1,1)).\n",
    "  - stride : Stride to use (default = (1,1)).\n",
    "  - act = Activation function (default = 'relu').\n",
    "  - bn = Bacth Normalization, if set to True, add a BN after each convolution (default = True).\n",
    "  - compression = Adds a compression convolution in the identity branch. If set to True, it will compress the input into the number of channels chosen with \"channels\" (default = False).\n",
    "  - kernel_init = Kernel initializer (default = 'he_normal')\n",
    "  \"\"\"\n",
    "\n",
    "  conv1 = Conv2D(\n",
    "      channels, \n",
    "      kernel,\n",
    "      strides=stride, \n",
    "      dilation_rate = dil,\n",
    "      activation=act,\n",
    "      padding='same',\n",
    "      kernel_initializer=kernel_init)(input)\n",
    "  norm1 = BatchNormalization()(conv1)  \n",
    "\n",
    "  conv2 = Conv2D(\n",
    "      channels, \n",
    "      kernel,\n",
    "      strides=stride, \n",
    "      dilation_rate = dil,\n",
    "      padding='same',\n",
    "      kernel_initializer=kernel_init)(norm1)\n",
    "  norm2 = BatchNormalization()(conv2)        \n",
    "\n",
    "  if channels < input.shape[-1]:\n",
    "    # print('COMPRESSION ON')\n",
    "    comp_conv = Conv2D(\n",
    "        channels, \n",
    "        kernel_size = (1,1),\n",
    "        padding='same',\n",
    "        kernel_initializer=kernel_init)(input)\n",
    "    comp_norm = BatchNormalization()(comp_conv)\n",
    "\n",
    "    summed_branches = add([comp_conv, conv2])\n",
    "\n",
    "  else:\n",
    "    # print('COMPRESSION OFF')\n",
    "    summed_branches = add([input, norm2])\n",
    "\n",
    "  output = ReLU()(summed_branches)\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "# x = np.arange(0,16, dtype= 'float').reshape(1,2,2,4) \n",
    "# res_block(x,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoXuGKF1poRl"
   },
   "source": [
    "Dual Receptive Field Res Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j0UF0nlCpnNO"
   },
   "outputs": [],
   "source": [
    "def dual_RF_block(input, channels, lrf_kernel, srf_kernel, lrf_dil = (3,3), srf_dil = (1,1), stride = (1,1), act= 'relu', bn= True, sp_dropout = False, kernel_init='he_normal'):\n",
    "  \"\"\"Builds the dual Receptive Field sub-block with the Small Receptive Field branch (SRF) and the Large Receptive Field branch (LRF). By our definition, only the dilation must be different with lrf_stride > srf_stride.\n",
    "  BE WAWARE: THE NUMBER OF FINAL OUTPUT CHANNELS IS 2*\"CHANNELS\" BECAUSE EACH RF BRANCH OUTPUTS A VOLUME OF \"CHANNELS\" DEPTH\n",
    "           +-------- LRF Branch --------+\n",
    "           |                            |\n",
    "  Input ---+                            +---> output\n",
    "           |                            |\n",
    "           +-------- SRF Branch --------+\n",
    "\n",
    "  - input : Block input volume.\n",
    "  - channels : Number of output channels. If \"channels\" value is inferior to input channels, a compression is automatically made with a 1*1conv in the identity branch. \n",
    "  - lrf_kernel : Kernel size to use in all LRF branch convolutions (except in the compression one).\n",
    "  - srf_kernel : Kernel size to use in all SRF branch convolutions (except in the compression one).\n",
    "  - lrf_dil : Dilation to use in the LRF branch (default = (1,1)).\n",
    "  - srf_dil : Dilation to use in the SRF branch (default = (1,1)).\n",
    "  - stride : Stride to use (default = (1,1)).\n",
    "  - act = Activation function (default = 'relu').\n",
    "  - bn = Bacth Normalization, if set to True, add a BN after each convolution (default = True).\n",
    "  - sp_dropout = Spatial dropout (default = False).\n",
    "  - compression = Adds a compression convolution in the identity branch. If set to True, it will compress the input into the number of channels chosen with \"channels\" (default = False).\n",
    "  - kernel_init = Kernel initializer (default = 'he_normal')\n",
    "  \"\"\"\n",
    "\n",
    "  lrf_block = res_block(input, channels, lrf_kernel, dil = lrf_dil, stride = stride, act= act, bn= bn,  kernel_init=kernel_init)\n",
    "  srf_block = res_block(input, channels, srf_kernel, dil = srf_dil, stride = stride, act= act, bn= bn,  kernel_init=kernel_init)\n",
    "\n",
    "  output = concatenate([lrf_block, srf_block], axis=-1)\n",
    "  \n",
    "  if sp_dropout:\n",
    "    output = SpatialDropout2D(sp_dropout)(output)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTuTUbzdtRTD"
   },
   "source": [
    "Type 1a Block and Type 1b Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-TJMFZiuuAtR"
   },
   "outputs": [],
   "source": [
    "def t1_block(input, channels, lrf_kernel, srf_kernel, lrf_dil = (3,3), srf_dil = (1,1), stride = (1,1), act= 'relu', bn= True, sp_dropout = False, maxpool= (2,2), kernel_init='he_normal'):\n",
    "  \"\"\"Builds the dual Receptive Field sub-block with the Small Receptive Field branch (SRF) and the Large Receptive Field branch (LRF). By our definition, only the dilation must be different with lrf_stride > srf_stride.\n",
    "  BE WAWARE: THE NUMBER OF FINAL OUTPUT CHANNELS IS 2*\"CHANNELS\" BECAUSE EACH RF BRANCH OUTPUTS A VOLUME OF \"CHANNELS\" DEPTH\n",
    "                          +-------- LRF Branch --------+\n",
    "                          |                            |\n",
    "  Input ---> Res Block ---+                            +-----> Maxpooling --> Output\n",
    "                          |                            |    |\n",
    "                          +-------- SRF Branch --------+    +-----> Output (for skip connection)\n",
    "\n",
    "  - input : Block input volume.\n",
    "  - channels : Number of output channels. If \"channels\" value is inferior to input channels, a compression is automatically made with a 1*1conv in the identity branch. \n",
    "  - lrf_kernel : Kernel size to use in all LRF branch convolutions (except in the compression one).\n",
    "  - srf_kernel : Kernel size to use in all SRF branch convolutions (except in the compression one).\n",
    "  - lrf_dil : Dilation to use in the LRF branch (default = (1,1)).\n",
    "  - srf_dil : Dilation to use in the SRF branch (default = (1,1)).\n",
    "  - stride : Stride to use (default = (1,1)).\n",
    "  - act = Activation function (default = 'relu').\n",
    "  - bn = Bacth Normalization, if set to True, add a BN after each convolution (default = True).\n",
    "  - sp_dropout = Spatial dropout (default = False).\n",
    "  - kernel_init = Kernel initializer (default = 'he_normal')\n",
    "  \"\"\"\n",
    "\n",
    "  #The base block uses the same values as the SRF branch, because by design they are the same\n",
    "  base_res_block_out = res_block(input, channels, srf_kernel, dil = srf_dil, stride = stride, act= act, bn= bn, kernel_init=kernel_init)\n",
    "\n",
    "  dual_rf_out = dual_RF_block(base_res_block, channels, lrf_kernel, srf_kernel, lrf_dil = lrf_dil, srf_dil = srf_dil, stride = stride, act= act, bn= bn, sp_dropout = sp_dropout, kernel_init=kernel_init)\n",
    "\n",
    "  if maxpool:\n",
    "    pool = MaxPooling2D(pool_size=maxpool)(dual_rf_out) \n",
    "    return pool, dual_rf_out\n",
    "\n",
    "  else:\n",
    "    return dual_rf_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVR6Y76ixcKZ"
   },
   "source": [
    "Type 2a Block and Type 2b BLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "se2QsNNBw6_l"
   },
   "outputs": [],
   "source": [
    "def t2_block(input, channels, lrf_kernel=(3,3), srf_kernel=(3,3), lrf_dil = (3,3), srf_dil = (1,1), stride = (1,1), act= 'relu', bn= True, sp_dropout = False, maxpool= (2,2),  kernel_init='he_normal'):\n",
    "  \"\"\"Builds the dual Receptive Field sub-block with the Small Receptive Field branch (SRF) and the Large Receptive Field branch (LRF). By our definition, only the dilation must be different with lrf_stride > srf_stride.\n",
    "  BE WAWARE: THE NUMBER OF FINAL OUTPUT CHANNELS IS 2*\"CHANNELS\" BECAUSE EACH RF BRANCH OUTPUTS A VOLUME OF \"CHANNELS\" DEPTH\n",
    "           +-------- LRF Branch --------+\n",
    "           |                            |\n",
    "  Input ---+                            +-----> Maxpooling --> Output\n",
    "           |                            |    |\n",
    "           +-------- SRF Branch --------+    +-----> Output (for skip connection)\n",
    "\n",
    "  - input : Block input volume.\n",
    "  - channels : Number of output channels.\n",
    "  - lrf_kernel : Kernel size to use in all LRF branch convolutions (except in the compression one).\n",
    "  - srf_kernel : Kernel size to use in all SRF branch convolutions (except in the compression one).\n",
    "  - lrf_dil : Dilation to use in the LRF branch (default = (1,1)).\n",
    "  - srf_dil : Dilation to use in the SRF branch (default = (1,1)).\n",
    "  - stride : Stride to use (default = (1,1)).\n",
    "  - act = Activation function (default = 'relu').\n",
    "  - bn = Bacth Normalization, if set to True, add a BN after each convolution (default = True).\n",
    "  - sp_dropout = Spatial dropout (default = False).\n",
    "  - compression = Adds a compression convolution in the identity branch. If set to True, it will compress the input into the number of channels chosen with \"channels\" (default = False).\n",
    "  - kernel_init = Kernel initializer (default = 'he_normal')\n",
    "  \"\"\"\n",
    "\n",
    "  dual_rf_out = dual_RF_block(input, channels, lrf_kernel, srf_kernel, lrf_dil = lrf_dil, srf_dil = srf_dil, stride = stride, act= act, bn= bn, sp_dropout = sp_dropout, kernel_init=kernel_init)\n",
    "\n",
    "  if maxpool:\n",
    "    pool = MaxPooling2D(pool_size=maxpool)(dual_rf_out)\n",
    "    return pool, dual_rf_out\n",
    "  else:\n",
    "    return dual_rf_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCip--sAv5rm"
   },
   "source": [
    "Attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UmLTCCp8w-1U"
   },
   "outputs": [],
   "source": [
    "def chan_attn_module(input):\n",
    "  glob_avg = GlobalAveragePooling2D()(input)\n",
    "  # print('global avg shape', glob_avg.shape) \n",
    "  # print('global avg ', glob_avg)\n",
    "  \n",
    "  # chan_conv1 = Conv2D(glob_avg.shape[-1], \n",
    "  #     1,\n",
    "  #     1,\n",
    "  #     activation = 'relu',\n",
    "  #     padding='same',\n",
    "  #     kernel_initializer='he_normal')(glob_avg)\n",
    "  # chan_weights = Conv2D(glob_avg.shape[-1], \n",
    "  #     1,\n",
    "  #     1,\n",
    "  #     activation = 'sigmoid',\n",
    "  #     padding='same',\n",
    "  #     kernel_initializer='he_normal')(chan_conv1)\n",
    "\n",
    "  chan_att_DL1 = Dense(glob_avg.shape[-1]/2, activation= 'relu')(glob_avg)\n",
    "  # print(chan_att_DL1.shape)\n",
    "  chan_att_DL2 = Dense(chan_att_DL1.shape[-1]*2, activation= 'sigmoid')(chan_att_DL1)\n",
    "  # print(chan_att_DL2.shape) \n",
    "  # print(chan_att_DL2) \n",
    "  chan_att = multiply([chan_att_DL2, input])\n",
    "  return chan_att \n",
    "\n",
    "\n",
    "\n",
    "def sp_attn_module(input):\n",
    "  spacial_weights = Conv2D(\n",
    "      1, \n",
    "      1,\n",
    "      strides=1, \n",
    "      activation = 'sigmoid',\n",
    "      padding='same',\n",
    "      kernel_initializer='he_normal')(input)\n",
    "    \n",
    "  # print('Spacial_weigths shape', spacial_weights.shape)\n",
    "  # print(\"Spacial_weihts :\", spacial_weights)\n",
    "  spacial_att = multiply([spacial_weights,input])\n",
    "\n",
    "  # print(\"spacial_att shape:\", spacial_att.shape)\n",
    "  return spacial_att\n",
    "\n",
    "def sc_att_module(input_volume):\n",
    "  c = chan_attn_module(input_volume)\n",
    "  s = sp_attn_module(input_volume)\n",
    "  att_out = s+c\n",
    "  # print(att_out.shape)\n",
    "  return att_out\n",
    "\n",
    "# from tensorflow import random\n",
    "\n",
    "# input_shape = (1, 28, 28, 4)\n",
    "# x = random.normal(input_shape)\n",
    "\n",
    "# x = np.arange(0,16, dtype= 'float').reshape(1,2,2,4) \n",
    "# print(\"X: \",x)\n",
    "\n",
    "# chan_att = sc_att_module(x)\n",
    "\n",
    "# print(\"ATT:\",chan_att)-+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWz6-UrIOjrb"
   },
   "source": [
    "Focal Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0s4MEerPOjDw"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "def tversky(y_true, y_pred):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.9\n",
    "    smooth = 1\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return K.pow((1-pt_1), gamma)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2])\n",
    "    union = K.sum(y_true, axis=[1,2]) + K.sum(y_pred, axis=[1,2])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "#Keras\n",
    "def IoULoss(targets, inputs, smooth=1):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    total = K.sum(targets) + K.sum(inputs)\n",
    "    union = total - intersection\n",
    "    \n",
    "    IoU = (intersection + smooth) / (union + smooth)\n",
    "    return 1 - IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFnfjN7BPqGx"
   },
   "source": [
    "#**Model construction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rl07fT8dPzfm",
    "outputId": "1dd96586-953d-4199-b2e3-12b5ebca5412"
   },
   "outputs": [],
   "source": [
    "def unet(pretrained_weights=None, baseHW=8, input_size=(650, 650, 1), loss= focal_tversky, model_name='UNet_t2_att', sp_dropout = False, learning_rate = 1e-4, metrics = ['accuracy', dsc]):\n",
    "\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    base_volume = res_block(inputs,baseHW,3)\n",
    "    # print(base_volume.shape)\n",
    "\n",
    "    pool1,skip1 = t2_block(base_volume, baseHW, sp_dropout= sp_dropout) #output depth 2x16 = 32\n",
    "\n",
    "    # print(pool1.shape)\n",
    "    pool2,skip2 = t2_block(pool1, baseHW*2) #output depth 2x32 = 64\n",
    "\n",
    "    # print(pool2.shape)    \n",
    "    pool3,skip3 = t2_block(pool2, baseHW*4) #output depth 2x64 = 128\n",
    "\n",
    "    # print(pool3.shape)\n",
    "    center = t2_block(pool3, baseHW*8, maxpool=False) #output depth 2x128 = 256\n",
    "\n",
    "    up3 = Conv2DTranspose(baseHW*8,4,2,padding=\"same\")(center) #output depth 128\n",
    "    am3 = sc_att_module(concatenate([up3, skip3])) #output depth 256\n",
    "    D3 = t2_block(am3,baseHW*4, maxpool=False) #output depth 2x32 = 64\n",
    "\n",
    "    up2 = Conv2DTranspose(baseHW*4,4,2,padding=\"same\")(D3) #output depth 32\n",
    "    am2 = sc_att_module(concatenate([up2, skip2])) #output depth 64\n",
    "    D2 = t2_block(am2,baseHW*2, maxpool=False) #output depth 2x16 = 32\n",
    "\n",
    "    up1 = Conv2DTranspose(baseHW*2,4,2,padding=\"same\")(D2) #output depth 16 \n",
    "    am1 = sc_att_module(concatenate([up1, skip1])) #output depth 32\n",
    "    D1 = t2_block(am1,baseHW, maxpool=False) #output depth 2x8 = 16\n",
    "\n",
    "    out_1 = res_block(D1,baseHW,3)\n",
    "\n",
    "    out_conv = Conv2D(1, 1, activation='sigmoid', padding='same')(out_1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out_conv, name=model_name)\n",
    "\n",
    "    # compilation\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss=loss, metrics=metrics)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    if pretrained_weights:\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    model.save(model_name)\n",
    "\n",
    "    #plot_model(model, show_shapes=True)\n",
    "    return model\n",
    "\n",
    "    #model = fass_model(input_size=(240, 240, 1), loss=focal_tversky, model_name='test', sp_dropout = 0.15, learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_membrane(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xp-BsBrZMTG"
   },
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "GFjIIR8cb5PY",
    "outputId": "a640d497-1c21-4277-cfb9-3f41b5524ffc"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from numpy import random\n",
    "\n",
    "# def shuffle_dataset(prob, source_folder, source_images, source_masks, dest_folder):\n",
    "\t\n",
    "# \t# masks = os.listdir(source_folder + source_masks)\n",
    "# \tif source_folder[-1] != '/':\n",
    "# \t\tsource_folder + '/'\n",
    "# \tif source_images[-1] != '/':\n",
    "# \t\tsource_images += '/'\n",
    "# \tif source_masks[-1] != '/':\n",
    "# \t\tsource_masks += '/' \n",
    "# \tif dest_folder[-1] != '/':\n",
    "# \t\tdest_folder += '/' \n",
    "# \tif not os.path.exists(dest_folder):\n",
    "# \t\tos.makedirs(dest_folder)\n",
    "# \t\tos.makedirs(dest_folder+'images/')\n",
    "# \t\tos.makedirs(dest_folder+'masks/')\n",
    "  \n",
    "\n",
    "\n",
    "# \tfiles = os.listdir(source_folder + source_images)\n",
    "# \tfor f in files :\n",
    "# \t\tif random.rand(1) < prob:\n",
    "# \t\t\tshutil.move(source_folder+source_images+f, dest_folder+'images/')\n",
    "# \t\t\tshutil.move(source_folder+source_masks+f, dest_folder+'masks/')\n",
    "\n",
    "# \treturn (dest_folder+'train/', dest_folder+'test/')\n",
    " \n",
    "# shuffle_dataset(0.3,'/content/drive/MyDrive/Drive projet Deep Learning FOR/0 - Ressources du projet précédent/original_dataset/','images','masks/','/content/current_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MLj4JmzGZSBu"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "\n",
    "\n",
    "\n",
    "def testGenerator(test_path, image_path, mask_path, target_size=(672,672), flag_multi_class=False, as_gray=True):\n",
    "    if test_path[-1] != '/':\n",
    "        test_path + '/'\n",
    "    if image_path[-1] != '/':\n",
    "        image_path += '/'\n",
    "    if mask_path[-1] != '/':\n",
    "        mask_path += '/' \n",
    "\n",
    "    for f in os.listdir(test_path + image_path):\n",
    "        # print(counter)\n",
    "        # counter += 1\n",
    "        img = io.imread(test_path + image_path + f, as_gray=as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img, target_size)\n",
    "        img = np.reshape(img, img.shape + (1,)\n",
    "                         ) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img, (1,) + img.shape)\n",
    "        #img = np.concatenate((img, np.flip(img, 1)), axis=3)\n",
    "\n",
    "        mask = io.imread(test_path + image_path + f, as_gray=as_gray)\n",
    "        mask = mask / 255\n",
    "        mask = trans.resize(mask, target_size)\n",
    "        mask = np.reshape(mask, mask.shape + (1,)\n",
    "                         ) if (not flag_multi_class) else mask\n",
    "        mask = np.reshape(mask, (1,) + mask.shape)\n",
    "\n",
    "        yield (img, mask)\n",
    "\n",
    "def labelVisualize(num_class, color_dict, img):\n",
    "    img = img[:, :, 0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i, :] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "\n",
    "def saveResult(save_path, npyfile, flag_multi_class=False, num_class=2):\n",
    "    for i, item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class, COLOR_DICT,\n",
    "                             item) if flag_multi_class else item[:, :, 0]\n",
    "        io.imsave(os.path.join(save_path, \"%d_predict.png\" % i), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDiW_cK6bTsj"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using another dataset to train model eand test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YMk9PQG0bZSv",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.696, max:    0.783, cur:    0.782)\n",
      "\tvalidation       \t (min:    0.976, max:    0.978, cur:    0.977)\n",
      "Loss\n",
      "\ttraining         \t (min:    0.518, max:    0.654, cur:    0.518)\n",
      "\tvalidation       \t (min:    0.320, max:    0.425, cur:    0.320)\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.5185 - accuracy: 0.7816 - val_loss: 0.3203 - val_accuracy: 0.9774\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.7807\n",
      "Epoch 00008: loss improved from 0.51847 to 0.51708, saving model to models/model_17_membrane\\model_17_membrane_lowres.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f69c4e29f468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1300\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1979\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    130\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 131\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "\n",
    "\n",
    "data_gen_args_1 = dict(featurewise_center=False,\n",
    "                         featurewise_std_normalization=False,\n",
    "                         rotation_range=90,\n",
    "                         width_shift_range=0.15,\n",
    "                         height_shift_range=0.15,\n",
    "                         zoom_range=0.3,\n",
    "                         horizontal_flip = True,\n",
    "                         shear_range = 0.08,\n",
    "                         fill_mode = 'nearest',\n",
    "                         rescale = 1./255)\n",
    "\n",
    "\n",
    "data_gen_args_2 = dict(featurewise_center=False,\n",
    "                         featurewise_std_normalization=False,\n",
    "                         fill_mode = 'nearest',\n",
    "                         rescale = 1./255)\n",
    "\n",
    "\n",
    "\n",
    "dim_image = 256\n",
    "batch_size = 5\n",
    "target_size = (dim_image,dim_image)\n",
    "\n",
    "model_index = '17_membrane'\n",
    "model_path = f\"models/model_{model_index}\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "    \n",
    "\n",
    "#train_data_generator = trainGenerator(batch_size,'test_dataset/unet-master/data/membrane/train/','image','label',data_gen_args, TEST_TRANSFORM,target_size=target_size, image_save_prefix=None, mask_save_prefix=None, save_to_dir = None)\n",
    "#validation_data_generator = validationGenerator('test_dataset/unet-master/data/membrane/test/','image','label',target_size=target_size)\n",
    "#train_data_generator = trainGenerator(batch_size,'old_dataset/train/','images','masks',data_gen_args, TEST_TRANSFORM,target_size=target_size, image_save_prefix=None, mask_save_prefix=None, save_to_dir = None)\n",
    "#validation_data_generator = validationGenerator('old_dataset/test/','images','masks',target_size=target_size)\n",
    "\n",
    "\n",
    "train_generator = trainGenerator(5,'test_dataset/unet-master/data/membrane/train', 'image','label',data_gen_args_1)\n",
    "\n",
    "test_generator = trainGenerator(5,'test_dataset/unet-master/data/membrane/test', 'image','label',data_gen_args_2)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "baseHW = 8\n",
    "#model = unet(input_size=(dim_image, dim_image, 1),baseHW=baseHW, loss='binary_crossentropy', model_name=f\"{model_path}/model_{model_index}_lowres\", sp_dropout = 0.15, learning_rate = 1e-4)\n",
    "model = unet_membrane()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    model_path+f\"/model_{model_index}_lowres.h5\", monitor='loss', verbose=1, save_best_only=True, mode=\"min\")\n",
    "\n",
    "\n",
    "live_loss = PlotLossesKerasTF()\n",
    "\n",
    "\n",
    "hstry = model.fit(\n",
    "    x = train_generator,\n",
    "    batch_size = None,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[model_checkpoint,live_loss],\n",
    "    validation_split=None,\n",
    "    validation_data= test_generator,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch= np.ceil(30 / batch_size),\n",
    "    validation_steps= np.ceil(30 / batch_size),\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=1,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "\n",
    "#with open(f\"{model_path}/trainHistoryDict_{model_index}\", 'wb') as file_pi:\n",
    "#        pickle.dump(hstry.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 189ms/step - loss: 0.6932 - accuracy: 3.1962e-05\n",
      "      2/Unknown - 0s 62ms/stepWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_predict_batch_end` time: 0.1237s). Check your callbacks.\n",
      "30/30 [==============================] - 4s 130ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\0_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\1_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\2_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\3_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\4_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\5_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\6_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\7_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\8_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\9_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\10_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\11_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\12_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\13_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\14_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\15_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\16_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\17_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\18_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\19_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\20_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\21_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\22_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\23_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\24_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\25_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\26_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\27_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\28_predict.png is a low contrast image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_test_17_membrane\\29_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 0s 63ms/stepWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_predict_batch_end` time: 0.1307s). Check your callbacks.\n",
      "30/30 [==============================] - 4s 133ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\0_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\1_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\2_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\3_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\4_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\5_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\6_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\7_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\8_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\9_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\10_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\11_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\12_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\13_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\14_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\15_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\16_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\17_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\18_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\19_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\20_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\21_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\22_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\23_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\24_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\25_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\26_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\27_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\28_predict.png is a low contrast image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\20100\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: UserWarning: models/model_17_membrane/results_train_17_membrane\\29_predict.png is a low contrast image\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f\"{model_path}/model_{model_index}_lowres.h5\")\n",
    "        \n",
    "test_generator = testGenerator('test_dataset/unet-master/data/membrane/test/', \n",
    "               'image',\n",
    "               'label')\n",
    "#test_data_generator = trainGenerator('test_dataset/unet-master/data/membrane/test/','image','label',target_size=target_size)\n",
    "#test_data_generator = trainGenerator('old_dataset/test/','images','masks',target_size=target_size)\n",
    "model.evaluate(test_generator,verbose=1)\n",
    "\n",
    "test_generator = testGenerator('test_dataset/unet-master/data/membrane/test/', 'image','label')\n",
    "\n",
    "#test_data_generator = testGenerator('test_dataset/unet-master/data/membrane/test/','image','label',target_size=target_size)\n",
    "#test_data_generator = testGenerator('old_dataset/test/','images','masks',target_size=target_size)\n",
    "results = model.predict(test_generator,verbose=1)\n",
    "\n",
    "if not os.path.exists(f\"{model_path}/results_test_{model_index}\"):\n",
    "    os.mkdir(f\"{model_path}/results_test_{model_index}\")\n",
    "saveResult(f\"{model_path}/results_test_{model_index}\",results)\n",
    "\n",
    "test_train_generator = testGenerator('test_dataset/unet-master/data/membrane/train/', \n",
    "               'image',\n",
    "               'label')\n",
    "\n",
    "#test_data_generator = testGenerator('test_dataset/unet-master/data/membrane/test/','image','label',target_size=target_size)\n",
    "#test_data_generator = testGenerator('old_dataset/test/','images','masks',target_size=target_size)\n",
    "results = model.predict(test_train_generator,verbose=1)\n",
    "\n",
    "if not os.path.exists(f\"{model_path}/results_train_{model_index}\"):\n",
    "    os.mkdir(f\"{model_path}/results_train_{model_index}\")\n",
    "saveResult(f\"{model_path}/results_train_{model_index}\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_build_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
